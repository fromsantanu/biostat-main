## **🧬 Chapter 5.5: Area Under the Curve (AUC)**

### **📖 Introduction**

In ROC analysis, the **Area Under the Curve (AUC)** provides a **single summary measure** of a test or model’s ability to discriminate between:

✅ **Positive cases (diseased)**
✅ **Negative cases (non-diseased)**

---

### **🔍 What is AUC?**

The **AUC** is the area under the ROC curve, ranging from:

* **0.5:** No discrimination (random classifier)
* **1.0:** Perfect discrimination

✅ Represents the **probability that the test or model ranks a randomly chosen positive instance higher than a randomly chosen negative instance**.

---

### **📝 Key Interpretation**

| **AUC Value**   | **Interpretation**       |
| --------------- | ------------------------ |
| **0.90 – 1.00** | Excellent                |
| **0.80 – 0.90** | Good                     |
| **0.70 – 0.80** | Fair                     |
| **0.60 – 0.70** | Poor                     |
| **0.50 – 0.60** | Fail (no discrimination) |

---

### **💡 Advantages of AUC**

✅ **Threshold-independent:** Summarises performance across all possible cut-offs
✅ Useful for comparing **different tests or models**

---

### **🔬 Practical Example**

Using the **previous dataset**:

| **Patient** | **Predicted Probability** | **Actual Outcome** |
| ----------- | ------------------------- | ------------------ |
| 1           | 0.90                      | 1                  |
| 2           | 0.80                      | 1                  |
| 3           | 0.70                      | 0                  |
| 4           | 0.60                      | 1                  |
| 5           | 0.50                      | 0                  |
| 6           | 0.40                      | 0                  |
| 7           | 0.30                      | 1                  |
| 8           | 0.20                      | 0                  |
| 9           | 0.10                      | 0                  |
| 10          | 0.05                      | 0                  |

---

### **🖥️ Implementation in Python**

Using **scikit-learn for AUC calculation**:

```python
# Install if not installed
# pip install scikit-learn

import pandas as pd
from sklearn.metrics import roc_auc_score

# Create data
data = pd.DataFrame({
    'prob': [0.90,0.80,0.70,0.60,0.50,0.40,0.30,0.20,0.10,0.05],
    'actual': [1,1,0,1,0,0,1,0,0,0]
})

# Calculate AUC
auc_value = roc_auc_score(data['actual'], data['prob'])

print(f"AUC: {auc_value:.2f}")
```

---

### **🔑 Interpretation**

✅ **AUC = 0.88** (example output) indicates **good discrimination ability**.

---

### **💡 Limitations of AUC**

❌ Does not provide information on **specific thresholds** for decision-making
❌ May be **misleading if data is imbalanced** (e.g. very few positive cases)

---

### **🎯 Key Takeaways**

✅ **AUC** summarises **overall test or model accuracy** in distinguishing positive and negative cases
✅ Higher AUC indicates **better discriminatory performance**
✅ Should be used with **ROC curves and clinical considerations** for threshold selection

---

## **🎓 End of Chapter V: Diagnostic Test Evaluation**

You have now covered:

1. **Sensitivity and Specificity**
2. **Positive Predictive Value (PPV) and Negative Predictive Value (NPV)**
3. **Receiver Operating Characteristic (ROC) Curves**
4. **Area Under the Curve (AUC)**

---
