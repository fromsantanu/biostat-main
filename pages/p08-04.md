## **ğŸ§¬ Bayesian Regression Models**

### **ğŸ“– Introduction**

**Bayesian regression models** extend Bayesian inference to **regression analysis**, allowing:

âœ… Incorporation of **prior beliefs** about regression parameters
âœ… Direct probabilistic interpretation of estimates and intervals
âœ… Greater flexibility for **complex hierarchical and adaptive models**

---

### **ğŸ” What is Bayesian Regression?**

In Bayesian regression:

* **Parameters (Î², ÏƒÂ²)** are treated as **random variables** with prior distributions
* The posterior distribution combines:

$$
Posterior \propto Likelihood \times Prior
$$

âœ… Provides **full posterior distributions** rather than single point estimates.

---

### **ğŸ“ Key Concepts**

1. **Prior:** Belief about regression coefficients before seeing data (e.g. Î² \~ Normal(0, 10)).
2. **Likelihood:** Probability of observed data given parameters (as in classical regression).
3. **Posterior:** Updated belief about parameters after observing data.

---

### **ğŸ’¡ When to Use**

âœ… When **prior information** is available (e.g. from past studies)
âœ… For **small sample sizes**, where prior stabilises estimates
âœ… In **hierarchical or multilevel models**
âœ… For **probabilistic decision-making**

---

### **ğŸ”¬ Practical Example**

#### **Scenario**

A researcher models **systolic blood pressure (SBP)** as a function of **age** using Bayesian linear regression.

| **Patient** | **Age (years)** | **SBP (mmHg)** |
| ----------- | --------------- | -------------- |
| 1           | 45              | 130            |
| 2           | 50              | 135            |
| 3           | 55              | 138            |
| 4           | 60              | 145            |
| 5           | 65              | 150            |
| 6           | 70              | 160            |
| 7           | 75              | 165            |
| 8           | 80              | 170            |

---

### **Stepwise Bayesian Model**

1. **Model specification**

$$
SBP_i \sim Normal(Î¼_i, Ïƒ)
$$

$$
Î¼_i = Î²_0 + Î²_1 \times Age_i
$$

2. **Priors**

* Î²â‚€ \~ Normal(0, 100)
* Î²â‚ \~ Normal(0, 10)
* Ïƒ \~ HalfNormal(10)

---

### **ğŸ–¥ï¸ Implementation in Python**

Using **pymc3 for Bayesian regression**:

```python
# Install if not installed
# pip install pymc3 arviz

import pymc3 as pm
import arviz as az
import numpy as np

# Data
age = np.array([45,50,55,60,65,70,75,80])
sbp = np.array([130,135,138,145,150,160,165,170])

# Bayesian model
with pm.Model() as model:
    # Priors
    beta0 = pm.Normal('beta0', mu=0, sigma=100)
    beta1 = pm.Normal('beta1', mu=0, sigma=10)
    sigma = pm.HalfNormal('sigma', sigma=10)
    
    # Linear model
    mu = beta0 + beta1 * age
    
    # Likelihood
    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=sbp)
    
    # Sampling
    trace = pm.sample(2000, return_inferencedata=True, progressbar=False)

# Summarise results
print(az.summary(trace, var_names=['beta0','beta1','sigma']))
```

---

### **ğŸ”‘ Interpretation**

* **Î²â‚€:** Estimated intercept with credible interval
* **Î²â‚:** Estimated slope (change in SBP per year of age) with credible interval
* **Ïƒ:** Residual standard deviation

âœ… Credible intervals provide **direct probability statements** about parameters.

---

### **ğŸ’¡ Advantages**

âœ… Incorporates **prior information**
âœ… Provides **full posterior distributions**
âœ… Handles **complex hierarchical models** elegantly

---

### **ğŸ’¡ Limitations**

âŒ Requires **prior specification**
âŒ Computationally intensive for large models (requires MCMC sampling)

---

### **ğŸ¯ Key Takeaways**

âœ… **Bayesian regression models** combine prior beliefs and data evidence to estimate regression parameters
âœ… Results are interpreted as **probability distributions** for parameters
âœ… Widely used in **clinical trials, epidemiology, and hierarchical modeling**

---


