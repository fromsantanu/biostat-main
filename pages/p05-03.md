## **🧬 Receiver Operating Characteristic (ROC) Curves**

### **📖 Introduction**

In evaluating diagnostic tests (or prediction models), we often need to:

✅ Assess test performance across **all possible thresholds**
✅ Balance **sensitivity and specificity** for optimal decision-making

This is achieved using **Receiver Operating Characteristic (ROC) curves**.

---

### **🔍 What is a ROC Curve?**

A **ROC Curve** is a plot of:

* **Sensitivity (True Positive Rate)** on the y-axis
* **1 – Specificity (False Positive Rate)** on the x-axis

Each point on the curve represents a **different cut-off threshold** for classifying a test as positive.

---

### **📝 Key Concepts**

* **Perfect test:** ROC curve passes through the **top-left corner (100% sensitivity, 100% specificity)**
* **No discrimination (random guess):** ROC curve is the **diagonal line** from bottom-left to top-right

---

#### **Area Under the Curve (AUC)**

The **AUC** measures **overall test accuracy**:

✅ **AUC = 1.0:** Perfect discrimination
✅ **AUC = 0.5:** No discrimination (random)

---

### **💡 When to Use**

✅ To compare **diagnostic tests or models**
✅ To select **optimal cut-off thresholds** based on sensitivity-specificity trade-offs
✅ To assess **discrimination ability** of predictive models

---

### **🔬 Practical Example**

#### **Scenario**

A dataset contains **predicted probabilities** from a logistic regression model and **true disease status** (1 = disease, 0 = no disease).

| **Patient** | **Predicted Probability** | **Actual Outcome** |
| ----------- | ------------------------- | ------------------ |
| 1           | 0.90                      | 1                  |
| 2           | 0.80                      | 1                  |
| 3           | 0.70                      | 0                  |
| 4           | 0.60                      | 1                  |
| 5           | 0.50                      | 0                  |
| 6           | 0.40                      | 0                  |
| 7           | 0.30                      | 1                  |
| 8           | 0.20                      | 0                  |
| 9           | 0.10                      | 0                  |
| 10          | 0.05                      | 0                  |

---

### **🖥️ Implementation in Python**

Using **sklearn’s roc\_curve and auc functions**:

```python
# Install if not installed
# pip install scikit-learn

import pandas as pd
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Create data
data = pd.DataFrame({
    'prob': [0.90,0.80,0.70,0.60,0.50,0.40,0.30,0.20,0.10,0.05],
    'actual': [1,1,0,1,0,0,1,0,0,0]
})

# Calculate ROC curve
fpr, tpr, thresholds = roc_curve(data['actual'], data['prob'])

# Calculate AUC
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(6,5))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0,1],[0,1], color='grey', linestyle='--')
plt.xlabel('1 - Specificity (False Positive Rate)')
plt.ylabel('Sensitivity (True Positive Rate)')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()
```

---

### **🔑 Interpretation**

✅ **AUC value** reflects test/model discrimination:

* **0.90 – 1.0:** Excellent
* **0.80 – 0.90:** Good
* **0.70 – 0.80:** Fair
* **0.60 – 0.70:** Poor
* **0.50 – 0.60:** Fail

✅ ROC curve shape shows **trade-off between sensitivity and specificity**.

---

### **💡 Optimal Threshold Selection**

Choose cut-off based on:

* **Clinical priorities** (e.g. maximise sensitivity for screening)
* **Youden’s Index:** Sensitivity + Specificity – 1 (maximised value indicates best balance)

---

### **🎯 Key Takeaways**

✅ **ROC curves** assess test or model performance across **all thresholds**
✅ **AUC** quantifies overall discrimination ability
✅ Essential for **diagnostic test evaluation, logistic regression assessment, and predictive modelling**

---

Let me know if you wish to proceed with **Chapter 5.5: Area Under the Curve (AUC)** for an in-depth understanding of **its calculation, interpretation, and applications** in your diagnostic evaluation tutorial series.

