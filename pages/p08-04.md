## **🧬 Bayesian Regression Models**

### **📖 Introduction**

**Bayesian regression models** extend Bayesian inference to **regression analysis**, allowing:

✅ Incorporation of **prior beliefs** about regression parameters
✅ Direct probabilistic interpretation of estimates and intervals
✅ Greater flexibility for **complex hierarchical and adaptive models**

---

### **🔍 What is Bayesian Regression?**

In Bayesian regression:

* **Parameters (β, σ²)** are treated as **random variables** with prior distributions
* The posterior distribution combines:

$$
Posterior \propto Likelihood \times Prior
$$

✅ Provides **full posterior distributions** rather than single point estimates.

---

### **📝 Key Concepts**

1. **Prior:** Belief about regression coefficients before seeing data (e.g. β \~ Normal(0, 10)).
2. **Likelihood:** Probability of observed data given parameters (as in classical regression).
3. **Posterior:** Updated belief about parameters after observing data.

---

### **💡 When to Use**

✅ When **prior information** is available (e.g. from past studies)
✅ For **small sample sizes**, where prior stabilises estimates
✅ In **hierarchical or multilevel models**
✅ For **probabilistic decision-making**

---

### **🔬 Practical Example**

#### **Scenario**

A researcher models **systolic blood pressure (SBP)** as a function of **age** using Bayesian linear regression.

| **Patient** | **Age (years)** | **SBP (mmHg)** |
| ----------- | --------------- | -------------- |
| 1           | 45              | 130            |
| 2           | 50              | 135            |
| 3           | 55              | 138            |
| 4           | 60              | 145            |
| 5           | 65              | 150            |
| 6           | 70              | 160            |
| 7           | 75              | 165            |
| 8           | 80              | 170            |

---

### **Stepwise Bayesian Model**

1. **Model specification**

$$
SBP_i \sim Normal(μ_i, σ)
$$

$$
μ_i = β_0 + β_1 \times Age_i
$$

2. **Priors**

* β₀ \~ Normal(0, 100)
* β₁ \~ Normal(0, 10)
* σ \~ HalfNormal(10)

---

### **🖥️ Implementation in Python**

Using **pymc3 for Bayesian regression**:

```python
# Install if not installed
# pip install pymc3 arviz

import pymc3 as pm
import arviz as az
import numpy as np

# Data
age = np.array([45,50,55,60,65,70,75,80])
sbp = np.array([130,135,138,145,150,160,165,170])

# Bayesian model
with pm.Model() as model:
    # Priors
    beta0 = pm.Normal('beta0', mu=0, sigma=100)
    beta1 = pm.Normal('beta1', mu=0, sigma=10)
    sigma = pm.HalfNormal('sigma', sigma=10)
    
    # Linear model
    mu = beta0 + beta1 * age
    
    # Likelihood
    y_obs = pm.Normal('y_obs', mu=mu, sigma=sigma, observed=sbp)
    
    # Sampling
    trace = pm.sample(2000, return_inferencedata=True, progressbar=False)

# Summarise results
print(az.summary(trace, var_names=['beta0','beta1','sigma']))
```

---

### **🔑 Interpretation**

* **β₀:** Estimated intercept with credible interval
* **β₁:** Estimated slope (change in SBP per year of age) with credible interval
* **σ:** Residual standard deviation

✅ Credible intervals provide **direct probability statements** about parameters.

---

### **💡 Advantages**

✅ Incorporates **prior information**
✅ Provides **full posterior distributions**
✅ Handles **complex hierarchical models** elegantly

---

### **💡 Limitations**

❌ Requires **prior specification**
❌ Computationally intensive for large models (requires MCMC sampling)

---

### **🎯 Key Takeaways**

✅ **Bayesian regression models** combine prior beliefs and data evidence to estimate regression parameters
✅ Results are interpreted as **probability distributions** for parameters
✅ Widely used in **clinical trials, epidemiology, and hierarchical modeling**

---


